{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNbV7CjR40YOtcjoU4zqcb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjasfedo/eceg-lsb-lzw-huffman/blob/main/HUFFMAN/huffman_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KTP Faker"
      ],
      "metadata": {
        "id": "IOYPV8gYZcZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIxaLVkMZeFN",
        "outputId": "00a0f705-7e3f-4be6-9437-38f1a98f2814"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-33.3.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.17.0)\n",
            "Downloading Faker-33.3.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-33.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "class DummyKTPGenerator:\n",
        "    def __init__(self):\n",
        "        self.faker = Faker('id_ID')  # Use Indonesian locale\n",
        "        self.indonesian_jobs = [\n",
        "            \"Guru\", \"Dokter\", \"Petani\", \"Nelayan\", \"Pegawai Negeri\", \"Karyawan Swasta\",\n",
        "            \"Wiraswasta\", \"Mahasiswa\", \"Pelajar\", \"Pengacara\", \"Arsitek\", \"Insinyur\",\n",
        "            \"Pedagang\", \"Polisi\", \"Tentara\", \"Seniman\", \"Penulis\", \"Pilot\", \"Supir\",\n",
        "            \"Teknisi\", \"Pemadam Kebakaran\", \"Apoteker\"\n",
        "        ]\n",
        "\n",
        "    def generate_ktp(self):\n",
        "        \"\"\"Generate a single dummy KTP record.\"\"\"\n",
        "        nik = self.generate_nik()\n",
        "        name = self.faker.name()\n",
        "        birth_place = self.faker.city()\n",
        "        birth_date = self.faker.date_of_birth().strftime('%d-%m-%Y')\n",
        "        gender = random.choice(['Laki-Laki', 'Perempuan'])\n",
        "        blood_type = random.choice(['A', 'B', 'AB', 'O'])\n",
        "        address = self.faker.address().replace('\\n', ', ')\n",
        "        rt_rw = f\"{random.randint(1, 20)}/{random.randint(1, 20)}\"\n",
        "        kelurahan = self.faker.city_suffix()\n",
        "        religion = random.choice(['Islam', 'Kristen', 'Katolik', 'Hindu', 'Buddha', 'Konghucu'])\n",
        "        marital_status = random.choice(['Belum Kawin', 'Kawin', 'Cerai Hidup', 'Cerai Mati'])\n",
        "        occupation = random.choice(self.indonesian_jobs)  # Select random Indonesian job\n",
        "        nationality = 'WNI'  # Assuming all generated data is Indonesian\n",
        "        valid_until = 'SEUMUR HIDUP'\n",
        "\n",
        "        return {\n",
        "            'NIK': nik,\n",
        "            'Nama': name,\n",
        "            'Tempat/Tgl Lahir': f\"{birth_place}, {birth_date}\",\n",
        "            'Jenis Kelamin': gender,\n",
        "            'Gol Darah': blood_type,\n",
        "            'Alamat': address,\n",
        "            'RT/RW': rt_rw,\n",
        "            'Kel/Desa': kelurahan,\n",
        "            'Agama': religion,\n",
        "            'Status Perkawinan': marital_status,\n",
        "            'Pekerjaan': occupation,\n",
        "            'Kewarganegaraan': nationality,\n",
        "            'Berlaku Hingga': valid_until,\n",
        "        }\n",
        "\n",
        "    def generate_nik(self):\n",
        "        \"\"\"Generate a dummy NIK (Indonesian identity number).\"\"\"\n",
        "        province_code = random.randint(10, 34)  # Random province code\n",
        "        regency_code = random.randint(1, 99)   # Random regency code\n",
        "        district_code = random.randint(1, 99) # Random district code\n",
        "        date_of_birth = self.faker.date_of_birth()\n",
        "        birth_date_part = date_of_birth.strftime('%d%m%y')  # Format DDMMYY\n",
        "        random_sequence = random.randint(1000, 9999)       # Random sequence number\n",
        "        return f\"{province_code:02}{regency_code:02}{district_code:02}{birth_date_part}{random_sequence:04}\"\n",
        "\n",
        "    def generate_multiple_ktps(self, count=1):\n",
        "        \"\"\"Generate multiple dummy KTP records.\"\"\"\n",
        "        return [self.generate_ktp() for _ in range(count)]\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_ktp_data(ktp):\n",
        "        \"\"\"\n",
        "        Merge a single KTP dictionary into a formatted string with '#' as a separator.\n",
        "        Replace spaces with '%'.\n",
        "        \"\"\"\n",
        "        fields = [\n",
        "            ktp.get('NIK', ''),\n",
        "            ktp.get('Nama', ''),\n",
        "            ktp.get('Tempat/Tgl Lahir', ''),\n",
        "            ktp.get('Jenis Kelamin', ''),\n",
        "            ktp.get('Gol Darah', ''),\n",
        "            ktp.get('Alamat', ''),\n",
        "            ktp.get('RT/RW', ''),\n",
        "            ktp.get('Kel/Desa', ''),\n",
        "            ktp.get('Agama', ''),\n",
        "            ktp.get('Status Perkawinan', ''),\n",
        "            ktp.get('Pekerjaan', ''),\n",
        "            ktp.get('Kewarganegaraan', ''),\n",
        "            ktp.get('Berlaku Hingga', '')\n",
        "        ]\n",
        "        merged = '#'.join(fields)\n",
        "        return merged.replace(' ', '%')\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_multiple_ktps(ktps):\n",
        "        \"\"\"\n",
        "        Merge multiple KTP dictionaries into formatted strings with '#' as a separator.\n",
        "        Replace spaces with '%'.\n",
        "        \"\"\"\n",
        "        return [DummyKTPGenerator.merge_ktp_data(ktp) for ktp in ktps]\n"
      ],
      "metadata": {
        "id": "sjs6RAexZfbk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = DummyKTPGenerator()\n",
        "\n",
        "# Generate multiple dummy KTPs\n",
        "dummy_ktps = generator.generate_multiple_ktps(count=5)\n",
        "\n",
        "# Merge single KTP\n",
        "merged_ktp = generator.merge_ktp_data(dummy_ktps[0])\n",
        "print(\"Merged Single KTP:\", merged_ktp)\n",
        "\n",
        "# Merge multiple KTPs\n",
        "merged_ktps = generator.merge_multiple_ktps(dummy_ktps)\n",
        "print(\"Merged Multiple KTPs:\")\n",
        "for m_ktp in merged_ktps:\n",
        "    print(m_ktp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltMQLTJcZhS-",
        "outputId": "129ac58d-4efc-4c4b-e418-1609cbeb2a6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged Single KTP: 2437382209545148#Hasan%Farida#Parepare,%08-01-1934#Perempuan#A#Jalan%Pelajar%Pejuang%No.%4,%Depok,%PA%74120#18/7#Ville#Kristen#Belum%Kawin#Pilot#WNI#SEUMUR%HIDUP\n",
            "Merged Multiple KTPs:\n",
            "2437382209545148#Hasan%Farida#Parepare,%08-01-1934#Perempuan#A#Jalan%Pelajar%Pejuang%No.%4,%Depok,%PA%74120#18/7#Ville#Kristen#Belum%Kawin#Pilot#WNI#SEUMUR%HIDUP\n",
            "2919582802304398#Gawati%Suartini,%S.H.#Langsa,%29-11-2008#Perempuan#O#Gg.%Medokan%Ayu%No.%02,%Tegal,%Bengkulu%36366#1/7#Ville#Kristen#Cerai%Hidup#Pengacara#WNI#SEUMUR%HIDUP\n",
            "3389092401417245#Kayla%Hidayanto#Kendari,%13-06-2018#Laki-Laki#A#Jl.%M.T%Haryono%No.%717,%Sabang,%Sulawesi%Selatan%76046#4/12#Ville#Katolik#Kawin#Pelajar#WNI#SEUMUR%HIDUP\n",
            "2246350810236400#Lili%Riyanti#Pagaralam,%01-02-2009#Laki-Laki#B#Gang%Veteran%No.%087,%Banjarmasin,%Kalimantan%Timur%47661#9/5#Ville#Islam#Belum%Kawin#Pedagang#WNI#SEUMUR%HIDUP\n",
            "1766500111335873#Lidya%Santoso#Kupang,%02-12-1909#Laki-Laki#O#Gang%Sadang%Serang%No.%503,%Bontang,%Aceh%41294#18/13#Ville#Islam#Cerai%Mati#Teknisi#WNI#SEUMUR%HIDUP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the content to match or exceed 98304 characters\n",
        "repeated_data = (merged_ktps[0] * (98304 // len(merged_ktps[0]) + 1))[:98304]  # Truncate to exactly 98304 characters\n",
        "\n",
        "# Verify length\n",
        "print(len(repeated_data))  # Output: 98304"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isVlIv8WZiak",
        "outputId": "b18f1031-0dcc-4a61-e5ad-739ccd3178bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compression Metrics"
      ],
      "metadata": {
        "id": "joJGKJ6856Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CompressionMetrics:\n",
        "    def __init__(self, original_length, compressed_length):\n",
        "        \"\"\"\n",
        "        Initialize the class with original and compressed lengths.\n",
        "        \"\"\"\n",
        "        self.original_length = original_length\n",
        "        self.compressed_length = compressed_length\n",
        "\n",
        "    def calculate_ratio_of_compression(self):\n",
        "        \"\"\"\n",
        "        Calculate the Ratio of Compression (RC).\n",
        "        \"\"\"\n",
        "        if self.compressed_length > 0:\n",
        "            return self.original_length / self.compressed_length\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def calculate_compression_ratio(self):\n",
        "        \"\"\"\n",
        "        Calculate the Compression Ratio (CR) as a percentage.\n",
        "        \"\"\"\n",
        "        rc = self.calculate_ratio_of_compression()\n",
        "        return rc * 100\n",
        "\n",
        "    def calculate_space_saving_ratio(self):\n",
        "        \"\"\"\n",
        "        Calculate the Space Saving (SS) as a percentage.\n",
        "        \"\"\"\n",
        "        if self.compressed_length == 0:\n",
        "            return 100  # If no compression, assume full space saving\n",
        "        if self.original_length > 0:\n",
        "            cr = self.calculate_compression_ratio()\n",
        "            return 100 - cr\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def calculate_efficiency(self):\n",
        "        \"\"\"\n",
        "        Calculate compression efficiency as a percentage.\n",
        "        \"\"\"\n",
        "        if self.original_length > 0:\n",
        "            ratio = ((self.original_length - self.compressed_length) / self.original_length) * 100\n",
        "        else:\n",
        "            ratio = 0\n",
        "        return ratio\n",
        "\n",
        "    def get_compression_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculate and return all metrics: RC, CR, SS, and optionally compression efficiency.\n",
        "        \"\"\"\n",
        "        rc = self.calculate_ratio_of_compression()\n",
        "        cr = self.calculate_compression_ratio()\n",
        "        ss = self.calculate_space_saving_ratio()\n",
        "        efficiency = self.calculate_efficiency()\n",
        "\n",
        "        print(f\"Ratio of Compression (RC): {rc:.2f}\")\n",
        "        print(f\"Compression Ratio (CR): {cr:.2f}%\")\n",
        "        print(f\"Space Saving (SS): {ss:.2f}%\")\n",
        "        print(f\"Compression Efficiency: {efficiency:.2f}%\")\n",
        "\n",
        "        return rc, cr, ss, efficiency\n"
      ],
      "metadata": {
        "id": "I48NzfT9576c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huffman"
      ],
      "metadata": {
        "id": "fz8gw3B6Zf7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "from collections import Counter\n",
        "\n",
        "# HuffmanNode class for tree structure\n",
        "class HuffmanNode:\n",
        "    def __init__(self, char, freq):\n",
        "        self.char = char    # Character\n",
        "        self.freq = freq    # Frequency of the character\n",
        "        self.left = None    # Left child\n",
        "        self.right = None   # Right child\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        # This ensures that the priority queue is ordered by frequency (min-heap)\n",
        "        return self.freq < other.freq\n",
        "\n",
        "# HuffmanCoding class that encapsulates all methods for encoding and decoding\n",
        "class HuffmanCoding:\n",
        "    def __init__(self, text=None):\n",
        "        self.text = text\n",
        "        self.freq_table = None\n",
        "        self.huffman_tree = None\n",
        "        self.codebook = None\n",
        "        if text:\n",
        "            self.build_huffman(text)\n",
        "\n",
        "    # Step 2: Build the frequency table\n",
        "    def build_frequency_table(self):\n",
        "        \"\"\"Build a frequency table for the given text.\"\"\"\n",
        "        self.freq_table = Counter(self.text)\n",
        "        return self.freq_table\n",
        "\n",
        "    # Step 3: Build the Huffman Tree\n",
        "    def build_huffman_tree(self):\n",
        "        \"\"\"Build the Huffman Tree based on the frequency table.\"\"\"\n",
        "        # Create a priority queue (min-heap) with HuffmanNode objects\n",
        "        heap = [HuffmanNode(char, freq) for char, freq in self.freq_table.items()]\n",
        "        heapq.heapify(heap)\n",
        "\n",
        "        # Build the Huffman tree\n",
        "        while len(heap) > 1:\n",
        "            left = heapq.heappop(heap)\n",
        "            right = heapq.heappop(heap)\n",
        "\n",
        "            # Create a new internal node with these two nodes as children\n",
        "            merged = HuffmanNode(None, left.freq + right.freq)\n",
        "            merged.left = left\n",
        "            merged.right = right\n",
        "\n",
        "            # Push the merged node back to the heap\n",
        "            heapq.heappush(heap, merged)\n",
        "\n",
        "        # The heap will now contain only one node, which is the root of the Huffman tree\n",
        "        self.huffman_tree = heap[0]\n",
        "        return self.huffman_tree\n",
        "\n",
        "    # Step 4: Generate Huffman Codes\n",
        "    def generate_huffman_codes(self, node=None, prefix='', codebook=None):\n",
        "        \"\"\"Recursively generate Huffman codes for each character.\"\"\"\n",
        "        if codebook is None:\n",
        "            codebook = {}\n",
        "        if node is None:\n",
        "            node = self.huffman_tree\n",
        "\n",
        "        # If it's a leaf node, assign the prefix as the Huffman code for the character\n",
        "        if node.char is not None:\n",
        "            codebook[node.char] = prefix\n",
        "        else:\n",
        "            # Recursively assign the prefix to the left and right children\n",
        "            if node.left:\n",
        "                self.generate_huffman_codes(node.left, prefix + '0', codebook)\n",
        "            if node.right:\n",
        "                self.generate_huffman_codes(node.right, prefix + '1', codebook)\n",
        "\n",
        "        self.codebook = codebook\n",
        "        return self.codebook\n",
        "\n",
        "    # Step 5: Encode the text\n",
        "    def encode(self, text=None):\n",
        "        \"\"\"Encode the input text using the Huffman codebook.\"\"\"\n",
        "        if text is None:\n",
        "            text = self.text\n",
        "        encoded_text = ''.join(self.codebook[char] for char in text)\n",
        "\n",
        "        # Ensure the encoded text is a multiple of 8 bits (add padding if necessary)\n",
        "        padding = 8 - len(encoded_text) % 8\n",
        "        encoded_text += '0' * padding  # Add padding with '0's\n",
        "        return encoded_text, padding\n",
        "\n",
        "    # Step 6: Decode the encoded text\n",
        "    def decode(self, encoded_text, padding):\n",
        "        \"\"\"Decode the encoded text back to the original text.\"\"\"\n",
        "        # Remove the padding\n",
        "        encoded_text = encoded_text[:-padding]\n",
        "\n",
        "        decoded_text = []\n",
        "        node = self.huffman_tree\n",
        "        for bit in encoded_text:\n",
        "            # Traverse the tree based on the bits (0 for left, 1 for right)\n",
        "            if bit == '0':\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "\n",
        "            # If we reach a leaf node, append the character and reset the node to the root\n",
        "            if node.char is not None:\n",
        "                decoded_text.append(node.char)\n",
        "                node = self.huffman_tree\n",
        "\n",
        "        return ''.join(decoded_text)\n",
        "\n",
        "    # Main method to perform Huffman Encoding\n",
        "    def build_huffman(self, text):\n",
        "        \"\"\"Build the Huffman tree, generate codes, and encode the text.\"\"\"\n",
        "        self.text = text\n",
        "        self.build_frequency_table()\n",
        "        self.build_huffman_tree()\n",
        "        self.generate_huffman_codes()\n",
        "\n",
        "        encoded_text, padding = self.encode(text)\n",
        "        return encoded_text, self.codebook, self.huffman_tree, padding\n",
        "\n",
        "    # Method to perform Huffman Decoding\n",
        "    def huffman_decoding(self, encoded_text, padding):\n",
        "        \"\"\"Decode the encoded text back to the original string.\"\"\"\n",
        "        return self.decode(encoded_text, padding)\n",
        "\n",
        "    def get_compression_ratio(self, input_string, encoded_text):\n",
        "        \"\"\"Calculate the compression ratio using the formula:\n",
        "           ((original_bits - compressed_bits) / original_bits) * 100\n",
        "        \"\"\"\n",
        "        # Get the length of the input message in bits (original data)\n",
        "        original_bits = self.message_length_in_bits(input_string)\n",
        "\n",
        "        # Get the length of the compressed data in bits\n",
        "        compressed_bits = len(encoded_text)\n",
        "\n",
        "        # Calculate the compression ratio using the revised formula\n",
        "        if original_bits > 0:\n",
        "            ratio = ((original_bits - compressed_bits) / original_bits) * 100\n",
        "        else:\n",
        "            ratio = 0\n",
        "\n",
        "        return ratio\n",
        "\n",
        "    def encoded_text_length(self, encoded_text):\n",
        "        return len(encoded_text)\n",
        "\n",
        "    def message_length_in_bits(self, message):\n",
        "        \"\"\"Convert message to bits and return its length.\"\"\"\n",
        "        # Convert each character in the string to its binary representation (8 bits)\n",
        "        bits = ''.join(format(ord(c), '08b') for c in message)\n",
        "        return len(bits)\n",
        "\n",
        "    def decode_to_chars(self, encoded_text, padding):\n",
        "        \"\"\"Convert encoded bits (string of '0' and '1') to actual characters.\"\"\"\n",
        "        # Step 1: Group the bits into chunks of 8 (1 byte)\n",
        "        byte_chunks = [encoded_text[i:i+8] for i in range(0, len(encoded_text), 8)]\n",
        "\n",
        "        # Step 2: Convert each byte to an integer and then to a character\n",
        "        decoded_chars = []\n",
        "        for byte in byte_chunks:\n",
        "            # If the byte is not of length 8, pad it (this happens if the last chunk is incomplete)\n",
        "            byte = byte.ljust(8, '0')\n",
        "            byte_as_int = int(byte, 2)  # Convert the binary string to an integer\n",
        "            decoded_chars.append(chr(byte_as_int))  # Convert integer to character using chr()\n",
        "\n",
        "        return ''.join(decoded_chars)\n",
        "\n",
        "    def encode_text_to_bits(self, text):\n",
        "        \"\"\"Convert decoded text (characters) back to a bitstream.\"\"\"\n",
        "        bitstream = []\n",
        "\n",
        "        for char in text:\n",
        "            # Convert each character to its integer (ASCII/Unicode) value\n",
        "            char_int = ord(char)\n",
        "\n",
        "            # Convert the integer to binary and ensure it's 8 bits long (padded with leading zeros)\n",
        "            bitstream.append(f'{char_int:08b}')\n",
        "\n",
        "        return ''.join(bitstream)\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "\n",
        "# Input string\n",
        "text = (repeated_data * 4)[:-1]\n",
        "# Create HuffmanCoding object and perform encoding\n",
        "huffman_coding = HuffmanCoding(text)\n",
        "encoded_text, codebook, huffman_tree, padding = huffman_coding.build_huffman(text)\n",
        "\n",
        "# Display the encoded text and the codebook\n",
        "# print(\"Encoded Text:\", encoded_text)\n",
        "\n",
        "# Perform Huffman Decoding\n",
        "decoded_text = huffman_coding.huffman_decoding(encoded_text, padding)\n",
        "# print(\"Decoded Text:\", decoded_text)\n",
        "\n",
        "assert text == decoded_text\n",
        "\n",
        "# Get the bit length of the compressed data\n",
        "bit_length_message = huffman_coding.message_length_in_bits(text)\n",
        "print(f\"Original data bit length: {bit_length_message}\")\n",
        "\n",
        "# Get the bit length of the compressed data\n",
        "bit_length_compressed = len(encoded_text)\n",
        "print(f\"Compressed data bit length: {bit_length_compressed}\")\n",
        "\n",
        "# Get the compression ratio\n",
        "compression_ratio = huffman_coding.get_compression_ratio(text, encoded_text)\n",
        "print(f\"Compression ratio: {compression_ratio:.2f}%\")\n",
        "\n",
        "# Decode to characters\n",
        "decoded_text = huffman_coding.decode_to_chars(encoded_text, padding)\n",
        "# print(\"Decoded Text from Bits:\", decoded_text)\n",
        "\n",
        "# Convert the decoded text back to a bitstream\n",
        "bitstream_from_decoded = huffman_coding.encode_text_to_bits(decoded_text)\n",
        "# print(\"Bitstream from Decoded Text:\", bitstream_from_decoded)\n",
        "\n",
        "assert bitstream_from_decoded == encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2FzYVr9awCq",
        "outputId": "9d74dd22-3500-46f2-e3c1-8a171158d388"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data bit length: 3145720\n",
            "Compressed data bit length: 2039280\n",
            "Compression ratio: 35.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = CompressionMetrics(bit_length_message, bit_length_compressed)\n",
        "\n",
        "metrics.get_compression_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxpQBeRz6Dmx",
        "outputId": "af4db17e-9ea3-455e-9446-1c26da274be1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratio of Compression (RC): 1.54\n",
            "Compression Ratio (CR): 154.26%\n",
            "Space Saving (SS): -54.26%\n",
            "Compression Efficiency: 35.17%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.5425640422109763,\n",
              " 154.25640422109763,\n",
              " -54.256404221097625,\n",
              " 35.172869804051224)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Huffman"
      ],
      "metadata": {
        "id": "YME72NAjg1tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestHuffmanCoding(unittest.TestCase):\n",
        "\n",
        "    def test_build_frequency_table(self):\n",
        "        \"\"\"Test the building of frequency table from text.\"\"\"\n",
        "        text = \"hello\"\n",
        "        huffman = HuffmanCoding(text)\n",
        "\n",
        "        freq_table = huffman.build_frequency_table()\n",
        "        expected_freq = {'h': 1, 'e': 1, 'l': 2, 'o': 1}\n",
        "\n",
        "        self.assertEqual(freq_table, expected_freq, f\"Expected frequency table: {expected_freq}, but got: {freq_table}\")\n",
        "\n",
        "    def test_build_huffman_tree(self):\n",
        "        \"\"\"Test the construction of the Huffman Tree.\"\"\"\n",
        "        text = \"hello\"\n",
        "        huffman = HuffmanCoding(text)\n",
        "\n",
        "        huffman.build_huffman_tree()\n",
        "        root = huffman.huffman_tree\n",
        "\n",
        "        self.assertIsNotNone(root, \"Huffman tree root should not be None.\")\n",
        "        self.assertIsNone(root.char, \"Root node should be an internal node, not a leaf.\")\n",
        "\n",
        "    # def test_generate_huffman_codes(self):\n",
        "    #     \"\"\"Test the generation of Huffman codes.\"\"\"\n",
        "    #     text = \"hello\"\n",
        "    #     huffman = HuffmanCoding(text)\n",
        "\n",
        "    #     huffman.build_huffman_tree()\n",
        "    #     codebook = huffman.generate_huffman_codes()\n",
        "\n",
        "    #     # Sample check for codebook\n",
        "    #     expected_codebook = {'h': '00', 'e': '01', 'l': '10', 'o': '11'}\n",
        "\n",
        "    #     self.assertEqual(codebook, expected_codebook, f\"Expected codebook: {expected_codebook}, but got: {codebook}\")\n",
        "\n",
        "    def test_encode(self):\n",
        "        \"\"\"Test the encoding of the text.\"\"\"\n",
        "        text = \"hello\"\n",
        "        huffman = HuffmanCoding(text)\n",
        "\n",
        "        huffman.build_huffman_tree()\n",
        "        huffman.generate_huffman_codes()\n",
        "\n",
        "        encoded_text, padding = huffman.encode(text)\n",
        "\n",
        "        # Check if encoded text is not empty\n",
        "        self.assertGreater(len(encoded_text), 0, \"Encoded text should not be empty.\")\n",
        "\n",
        "        # Ensure that the padding is correct\n",
        "        self.assertTrue(0 <= padding < 8, f\"Padding should be between 0 and 7, but got {padding}.\")\n",
        "\n",
        "    def test_decode(self):\n",
        "        \"\"\"Test the decoding of the encoded text.\"\"\"\n",
        "        text = \"hello\"\n",
        "        huffman = HuffmanCoding(text)\n",
        "\n",
        "        huffman.build_huffman_tree()\n",
        "        huffman.generate_huffman_codes()\n",
        "\n",
        "        encoded_text, padding = huffman.encode(text)\n",
        "\n",
        "        decoded_text = huffman.decode(encoded_text, padding)\n",
        "\n",
        "        self.assertEqual(decoded_text, text, f\"Decoded text: {decoded_text} does not match original text: {text}.\")\n",
        "\n",
        "    def test_compression_ratio(self):\n",
        "        \"\"\"Test the compression ratio calculation.\"\"\"\n",
        "        original_text = \"hello\"\n",
        "        huffman = HuffmanCoding(original_text)\n",
        "\n",
        "        huffman.build_huffman_tree()\n",
        "        encoded_text, padding = huffman.encode(original_text)\n",
        "\n",
        "        compression_ratio = huffman.get_compression_ratio(original_text, encoded_text)\n",
        "\n",
        "        self.assertGreater(compression_ratio, 0, f\"Expected positive compression ratio, but got {compression_ratio}.\")\n",
        "\n",
        "    def test_huffman_decoding(self):\n",
        "        \"\"\"Test the decoding using huffman_decoding method.\"\"\"\n",
        "        text = \"hello\"\n",
        "        huffman = HuffmanCoding(text)\n",
        "\n",
        "        huffman.build_huffman_tree()\n",
        "        huffman.generate_huffman_codes()\n",
        "\n",
        "        encoded_text, padding = huffman.encode(text)\n",
        "\n",
        "        decoded_text = huffman.huffman_decoding(encoded_text, padding)\n",
        "\n",
        "        self.assertEqual(decoded_text, text, f\"Decoded text: {decoded_text} does not match original text: {text}.\")\n",
        "\n",
        "    def test_encoded_text_length(self):\n",
        "        \"\"\"Test the length of the encoded text.\"\"\"\n",
        "        text = \"hello\"\n",
        "        huffman = HuffmanCoding(text)\n",
        "\n",
        "        huffman.build_huffman_tree()\n",
        "        huffman.generate_huffman_codes()\n",
        "\n",
        "        encoded_text, padding = huffman.encode(text)\n",
        "\n",
        "        encoded_length = huffman.encoded_text_length(encoded_text)\n",
        "\n",
        "        # Check if length of encoded text is greater than 0\n",
        "        self.assertGreater(encoded_length, 0, f\"Encoded text length should be greater than 0, but got {encoded_length}.\")\n",
        "\n",
        "    # def test_decode_to_chars(self):\n",
        "    #     \"\"\"Test converting encoded bits back to characters.\"\"\"\n",
        "    #     text = \"hello\"\n",
        "    #     huffman = HuffmanCoding(text)\n",
        "\n",
        "    #     huffman.build_huffman_tree()\n",
        "    #     huffman.generate_huffman_codes()\n",
        "\n",
        "    #     encoded_text, padding = huffman.encode(text)\n",
        "\n",
        "    #     decoded_chars = huffman.decode_to_chars(encoded_text, padding)\n",
        "\n",
        "    #     self.assertEqual(decoded_chars, text, f\"Decoded characters: {decoded_chars} do not match the original text: {text}.\")\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTxZUnN3g3w9",
        "outputId": "3a27b302-1312-462e-b295-30908c86b185"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_build_frequency_table (__main__.TestHuffmanCoding)\n",
            "Test the building of frequency table from text. ... ok\n",
            "test_build_huffman_tree (__main__.TestHuffmanCoding)\n",
            "Test the construction of the Huffman Tree. ... ok\n",
            "test_compression_ratio (__main__.TestHuffmanCoding)\n",
            "Test the compression ratio calculation. ... ok\n",
            "test_decode (__main__.TestHuffmanCoding)\n",
            "Test the decoding of the encoded text. ... ok\n",
            "test_encode (__main__.TestHuffmanCoding)\n",
            "Test the encoding of the text. ... ok\n",
            "test_encoded_text_length (__main__.TestHuffmanCoding)\n",
            "Test the length of the encoded text. ... ok\n",
            "test_huffman_decoding (__main__.TestHuffmanCoding)\n",
            "Test the decoding using huffman_decoding method. ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 7 tests in 0.030s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7f8fa9ea4ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dump Code"
      ],
      "metadata": {
        "id": "cWg3LRWFaueU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len('0101001001001001010110010010101111100010111100111011110011100000110111101011101110010110010101001100011011101001111110001011110000011111100101011100100010001') / 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq1z4Aj5dxF4",
        "outputId": "8e43d3c0-a4b9-44e5-8563-5b4bfcd3e2ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.625"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len('0101001001001001010110010010101111100010111100111011110011100000110111101011101110010110010101001100011011101001111110001011110000011111100101011100100010001000')/ 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXw1-VlOdzro",
        "outputId": "74a5ed0b-0e4a-497c-fff7-f90cbad4c3b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49bFNy98YJ9_",
        "outputId": "e9f91720-1548-488f-e948-3ec4b4d7e5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Text: 0101001001001001010110010010101111100010111100111011110011100000110111101011101110010110010101001100011011101001111110001011110000011111100101011100100010001\n",
            "\n",
            "Huffman Codebook: {'n': '000', 's': '0010', 'm': '0011', 'h': '0100', 't': '01010', 'd': '01011', 'r': '01100', 'l': '01101', 'x': '01110', 'c': '01111', 'p': '10000', 'g': '10001', 'i': '1001', ' ': '101', 'u': '11000', 'o': '11001', 'f': '1101', 'e': '1110', 'a': '1111'}\n",
            "\n",
            "Decoded Text: this is an example for huffman encoding\n"
          ]
        }
      ],
      "source": [
        "import heapq  # For priority queue (min-heap)\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Define the HuffmanNode class\n",
        "class HuffmanNode:\n",
        "    def __init__(self, char, freq):\n",
        "        self.char = char    # Character\n",
        "        self.freq = freq    # Frequency of the character\n",
        "        self.left = None    # Left child\n",
        "        self.right = None   # Right child\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        # This ensures that the priority queue is ordered by frequency (min-heap)\n",
        "        return self.freq < other.freq\n",
        "\n",
        "# Step 2: Build the frequency table\n",
        "def build_frequency_table(text):\n",
        "    return Counter(text)\n",
        "\n",
        "# Step 3: Build the Huffman Tree\n",
        "def build_huffman_tree(freq_table):\n",
        "    # Step 1: Create a priority queue (min-heap) with HuffmanNode objects\n",
        "    heap = [HuffmanNode(char, freq) for char, freq in freq_table.items()]\n",
        "    heapq.heapify(heap)\n",
        "\n",
        "    # Step 2: Build the Huffman tree\n",
        "    while len(heap) > 1:\n",
        "        # Pop the two nodes with the smallest frequencies\n",
        "        left = heapq.heappop(heap)\n",
        "        right = heapq.heappop(heap)\n",
        "\n",
        "        # Create a new internal node with these two nodes as children\n",
        "        merged = HuffmanNode(None, left.freq + right.freq)\n",
        "        merged.left = left\n",
        "        merged.right = right\n",
        "\n",
        "        # Push the merged node back to the heap\n",
        "        heapq.heappush(heap, merged)\n",
        "\n",
        "    # The heap will now contain only one node, which is the root of the Huffman tree\n",
        "    return heap[0]\n",
        "\n",
        "# Step 4: Generate Huffman Codes\n",
        "def generate_huffman_codes(node, prefix='', codebook=None):\n",
        "    if codebook is None:\n",
        "        codebook = {}\n",
        "\n",
        "    # If it's a leaf node, assign the prefix as the Huffman code for the character\n",
        "    if node.char is not None:\n",
        "        codebook[node.char] = prefix\n",
        "    else:\n",
        "        # Recursively assign the prefix to the left and right children\n",
        "        if node.left:\n",
        "            generate_huffman_codes(node.left, prefix + '0', codebook)\n",
        "        if node.right:\n",
        "            generate_huffman_codes(node.right, prefix + '1', codebook)\n",
        "\n",
        "    return codebook\n",
        "\n",
        "# Step 5: Encode the text\n",
        "def encode(text, codebook):\n",
        "    return ''.join(codebook[char] for char in text)\n",
        "\n",
        "# Step 6: Decode the encoded text\n",
        "def decode(encoded_text, huffman_tree):\n",
        "    decoded_text = []\n",
        "    node = huffman_tree\n",
        "    for bit in encoded_text:\n",
        "        # Traverse the tree based on the bits (0 for left, 1 for right)\n",
        "        if bit == '0':\n",
        "            node = node.left\n",
        "        else:\n",
        "            node = node.right\n",
        "\n",
        "        # If we reach a leaf node, append the character and reset the node to the root\n",
        "        if node.char is not None:\n",
        "            decoded_text.append(node.char)\n",
        "            node = huffman_tree\n",
        "\n",
        "    return ''.join(decoded_text)\n",
        "\n",
        "# Step 7: Huffman Encoding\n",
        "def huffman_encoding(text):\n",
        "    # Step 1: Build frequency table\n",
        "    freq_table = build_frequency_table(text)\n",
        "\n",
        "    # Step 2: Build the Huffman tree\n",
        "    huffman_tree = build_huffman_tree(freq_table)\n",
        "\n",
        "    # Step 3: Generate Huffman codes\n",
        "    codebook = generate_huffman_codes(huffman_tree)\n",
        "\n",
        "    # Step 4: Encode the input text\n",
        "    encoded_text = encode(text, codebook)\n",
        "\n",
        "    return encoded_text, codebook, huffman_tree\n",
        "\n",
        "# Step 8: Huffman Decoding\n",
        "def huffman_decoding(encoded_text, huffman_tree):\n",
        "    # Step 1: Decode the encoded text\n",
        "    decoded_text = decode(encoded_text, huffman_tree)\n",
        "    return decoded_text\n",
        "\n",
        "# Example Usage\n",
        "\n",
        "# Input string\n",
        "text = \"this is an example for huffman encoding\"\n",
        "\n",
        "# Perform Huffman Encoding\n",
        "encoded_text, codebook, huffman_tree = huffman_encoding(text)\n",
        "\n",
        "# Display the encoded text and the codebook\n",
        "print(\"Encoded Text:\", encoded_text)\n",
        "print(\"\\nHuffman Codebook:\", codebook)\n",
        "\n",
        "# Perform Huffman Decoding\n",
        "decoded_text = huffman_decoding(encoded_text, huffman_tree)\n",
        "\n",
        "# Display the decoded text\n",
        "print(\"\\nDecoded Text:\", decoded_text)\n",
        "\n",
        "assert text == decoded_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "\n",
        "# Input string\n",
        "text = \"this is an example for huffman encoding\"\n",
        "\n",
        "# Perform Huffman Encoding\n",
        "encoded_text, codebook, huffman_tree = huffman_encoding(text)\n",
        "\n",
        "# Display the encoded text and the codebook\n",
        "print(\"Encoded Text:\", encoded_text)\n",
        "print(\"\\nHuffman Codebook:\", codebook)\n",
        "\n",
        "# Perform Huffman Decoding\n",
        "decoded_text = huffman_decoding(encoded_text, huffman_tree)\n",
        "\n",
        "# Display the decoded text\n",
        "print(\"\\nDecoded Text:\", decoded_text)\n",
        "\n",
        "assert text == decoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKAQvkGvZoqm",
        "outputId": "3851f485-2089-448c-df8a-94990c43adb9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Text: 0101001001001001010110010010101111100010111100111011110011100000110111101011101110010110010101001100011011101001111110001011110000011111100101011100100010001\n",
            "\n",
            "Huffman Codebook: {'n': '000', 's': '0010', 'm': '0011', 'h': '0100', 't': '01010', 'd': '01011', 'r': '01100', 'l': '01101', 'x': '01110', 'c': '01111', 'p': '10000', 'g': '10001', 'i': '1001', ' ': '101', 'u': '11000', 'o': '11001', 'f': '1101', 'e': '1110', 'a': '1111'}\n",
            "\n",
            "Decoded Text: this is an example for huffman encoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_bits(message):\n",
        "    # Convert each character in the string to its binary representation (8 bits)\n",
        "    bits = ''.join(format(ord(c), '08b') for c in message)\n",
        "    return bits\n",
        "\n",
        "def message_length_in_bits(message):\n",
        "    bits = string_to_bits(message)\n",
        "    return len(bits)\n",
        "\n",
        "# Example usage\n",
        "message = text\n",
        "bits = string_to_bits(message)\n",
        "length_in_bits = message_length_in_bits(message)\n",
        "\n",
        "print(f\"Message: {message}\")\n",
        "print(f\"Bits: {bits}\")\n",
        "print(f\"Length in bits: {length_in_bits}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZg5kM5gYoTf",
        "outputId": "2d509a47-71f2-48d9-b39a-b529102e9803"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: this is an example for huffman encoding\n",
            "Bits: 011101000110100001101001011100110010000001101001011100110010000001100001011011100010000001100101011110000110000101101101011100000110110001100101001000000110011001101111011100100010000001101000011101010110011001100110011011010110000101101110001000000110010101101110011000110110111101100100011010010110111001100111\n",
            "Length in bits: 312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# length_in_bits = message_length_in_bits(encoded_text)\n",
        "print(f\"Length in bits: {len(encoded_text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-DeM_bgY7Tu",
        "outputId": "575b6842-0356-4686-9a1a-c3f8995d3738"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length in bits: 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test repeat"
      ],
      "metadata": {
        "id": "vvoSvwhvaE66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_string_ktp = (repeated_data * 4)[:-1]"
      ],
      "metadata": {
        "id": "9A73EFpoZRRW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q8_BJPxKaEtb"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}