{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXiWS0H0yBk2IYbDPitID5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjasfedo/eceg-lsb-lzw-huffman/blob/main/LSB/lsb_image_compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtosWwl-isYv",
        "outputId": "4083ce20-7199-49a7-faaf-326a2a9bd958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install faker -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "class DummyKTPGenerator:\n",
        "    def __init__(self):\n",
        "        self.faker = Faker('id_ID')  # Use Indonesian locale\n",
        "        self.indonesian_jobs = [\n",
        "            \"Guru\", \"Dokter\", \"Petani\", \"Nelayan\", \"Pegawai Negeri\", \"Karyawan Swasta\",\n",
        "            \"Wiraswasta\", \"Mahasiswa\", \"Pelajar\", \"Pengacara\", \"Arsitek\", \"Insinyur\",\n",
        "            \"Pedagang\", \"Polisi\", \"Tentara\", \"Seniman\", \"Penulis\", \"Pilot\", \"Supir\",\n",
        "            \"Teknisi\", \"Pemadam Kebakaran\", \"Apoteker\"\n",
        "        ]\n",
        "\n",
        "    def generate_ktp(self):\n",
        "        \"\"\"Generate a single dummy KTP record.\"\"\"\n",
        "        nik = self.generate_nik()\n",
        "        name = self.faker.name()\n",
        "        birth_place = self.faker.city()\n",
        "        birth_date = self.faker.date_of_birth().strftime('%d-%m-%Y')\n",
        "        gender = random.choice(['Laki-Laki', 'Perempuan'])\n",
        "        blood_type = random.choice(['A', 'B', 'AB', 'O'])\n",
        "        address = self.faker.address().replace('\\n', ', ')\n",
        "        rt_rw = f\"{random.randint(1, 20)}/{random.randint(1, 20)}\"\n",
        "        kelurahan = self.faker.city_suffix()\n",
        "        religion = random.choice(['Islam', 'Kristen', 'Katolik', 'Hindu', 'Buddha', 'Konghucu'])\n",
        "        marital_status = random.choice(['Belum Kawin', 'Kawin', 'Cerai Hidup', 'Cerai Mati'])\n",
        "        occupation = random.choice(self.indonesian_jobs)  # Select random Indonesian job\n",
        "        nationality = 'WNI'  # Assuming all generated data is Indonesian\n",
        "        valid_until = 'SEUMUR HIDUP'\n",
        "\n",
        "        return {\n",
        "            'NIK': nik,\n",
        "            'Nama': name,\n",
        "            'Tempat/Tgl Lahir': f\"{birth_place}, {birth_date}\",\n",
        "            'Jenis Kelamin': gender,\n",
        "            'Gol Darah': blood_type,\n",
        "            'Alamat': address,\n",
        "            'RT/RW': rt_rw,\n",
        "            'Kel/Desa': kelurahan,\n",
        "            'Agama': religion,\n",
        "            'Status Perkawinan': marital_status,\n",
        "            'Pekerjaan': occupation,\n",
        "            'Kewarganegaraan': nationality,\n",
        "            'Berlaku Hingga': valid_until,\n",
        "        }\n",
        "\n",
        "    def generate_nik(self):\n",
        "        \"\"\"Generate a dummy NIK (Indonesian identity number).\"\"\"\n",
        "        province_code = random.randint(10, 34)  # Random province code\n",
        "        regency_code = random.randint(1, 99)   # Random regency code\n",
        "        district_code = random.randint(1, 99) # Random district code\n",
        "        date_of_birth = self.faker.date_of_birth()\n",
        "        birth_date_part = date_of_birth.strftime('%d%m%y')  # Format DDMMYY\n",
        "        random_sequence = random.randint(1000, 9999)       # Random sequence number\n",
        "        return f\"{province_code:02}{regency_code:02}{district_code:02}{birth_date_part}{random_sequence:04}\"\n",
        "\n",
        "    def generate_multiple_ktps(self, count=1):\n",
        "        \"\"\"Generate multiple dummy KTP records.\"\"\"\n",
        "        return [self.generate_ktp() for _ in range(count)]\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_ktp_data(ktp):\n",
        "        \"\"\"\n",
        "        Merge a single KTP dictionary into a formatted string with '#' as a separator.\n",
        "        Replace spaces with '%'.\n",
        "        \"\"\"\n",
        "        fields = [\n",
        "            ktp.get('NIK', ''),\n",
        "            ktp.get('Nama', ''),\n",
        "            ktp.get('Tempat/Tgl Lahir', ''),\n",
        "            ktp.get('Jenis Kelamin', ''),\n",
        "            ktp.get('Gol Darah', ''),\n",
        "            ktp.get('Alamat', ''),\n",
        "            ktp.get('RT/RW', ''),\n",
        "            ktp.get('Kel/Desa', ''),\n",
        "            ktp.get('Agama', ''),\n",
        "            ktp.get('Status Perkawinan', ''),\n",
        "            ktp.get('Pekerjaan', ''),\n",
        "            ktp.get('Kewarganegaraan', ''),\n",
        "            ktp.get('Berlaku Hingga', '')\n",
        "        ]\n",
        "        merged = '#'.join(fields)\n",
        "        return merged.replace(' ', '%')\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_multiple_ktps(ktps):\n",
        "        \"\"\"\n",
        "        Merge multiple KTP dictionaries into formatted strings with '#' as a separator.\n",
        "        Replace spaces with '%'.\n",
        "        \"\"\"\n",
        "        return [DummyKTPGenerator.merge_ktp_data(ktp) for ktp in ktps]\n"
      ],
      "metadata": {
        "id": "AeVx7XYEi2zK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = DummyKTPGenerator()\n",
        "\n",
        "# Generate multiple dummy KTPs\n",
        "dummy_ktps = generator.generate_multiple_ktps(count=5)\n",
        "\n",
        "# Merge single KTP\n",
        "merged_ktp = generator.merge_ktp_data(dummy_ktps[0])\n",
        "print(\"Merged Single KTP:\", merged_ktp)\n",
        "\n",
        "# Merge multiple KTPs\n",
        "merged_ktps = generator.merge_multiple_ktps(dummy_ktps)\n",
        "print(\"Merged Multiple KTPs:\")\n",
        "for m_ktp in merged_ktps:\n",
        "    print(m_ktp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PWNwnsji3QJ",
        "outputId": "b9b9839e-c961-4a75-a13b-1cbf0e4a51ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged Single KTP: 2910530601849930#Makuta%Waluyo,%S.Pt#Purwokerto,%28-11-2006#Perempuan#O#Jalan%Jayawijaya%No.%544,%Banjar,%Jawa%Tengah%36092#17/3#Ville#Islam#Kawin#Wiraswasta#WNI#SEUMUR%HIDUP\n",
            "Merged Multiple KTPs:\n",
            "2910530601849930#Makuta%Waluyo,%S.Pt#Purwokerto,%28-11-2006#Perempuan#O#Jalan%Jayawijaya%No.%544,%Banjar,%Jawa%Tengah%36092#17/3#Ville#Islam#Kawin#Wiraswasta#WNI#SEUMUR%HIDUP\n",
            "1450400502041863#Zamira%Wibisono#Purwokerto,%03-09-1925#Perempuan#A#Gang%Cihampelas%No.%5,%Pasuruan,%KU%00639#15/2#Ville#Buddha#Belum%Kawin#Petani#WNI#SEUMUR%HIDUP\n",
            "1562171206151362#Jumadi%Marbun#Balikpapan,%30-03-1911#Perempuan#A#Jl.%Ahmad%Dahlan%No.%89,%Palembang,%ST%82728#14/1#Ville#Katolik#Cerai%Mati#Insinyur#WNI#SEUMUR%HIDUP\n",
            "2502291804097008#dr.%Gabriella%Wulandari,%M.Farm#Tarakan,%17-08-2006#Laki-Laki#A#Jl.%Pelajar%Pejuang%No.%19,%Sabang,%Aceh%68345#19/4#Ville#Kristen#Cerai%Mati#Wiraswasta#WNI#SEUMUR%HIDUP\n",
            "2903840210739251#Cinta%Tamba#Cirebon,%12-09-1980#Laki-Laki#B#Gang%R.E%Martadinata%No.%48,%Padangpanjang,%Sulawesi%Selatan%01879#7/11#Ville#Hindu#Cerai%Hidup#Teknisi#WNI#SEUMUR%HIDUP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = merged_ktps[0]\n",
        "message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zBZC6X-zi4np",
        "outputId": "e4407bbb-58cd-434d-ee3d-1a674357373b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2910530601849930#Makuta%Waluyo,%S.Pt#Purwokerto,%28-11-2006#Perempuan#O#Jalan%Jayawijaya%No.%544,%Banjar,%Jawa%Tengah%36092#17/3#Ville#Islam#Kawin#Wiraswasta#WNI#SEUMUR%HIDUP'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "# URL to the raw image file\n",
        "url = \"https://raw.githubusercontent.com/mikolalysenko/lena/master/lena.png\"\n",
        "\n",
        "# Download the image\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    # Load the image using PIL\n",
        "    lena_image = Image.open(io.BytesIO(response.content))\n",
        "    lena_image.show()  # Display the image (optional)\n",
        "    lena_image.save(\"lena.png\")  # Save the image locally\n",
        "else:\n",
        "    print(\"Failed to download the image.\")"
      ],
      "metadata": {
        "id": "wAZtT_2Mi6AB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "LENA_IMG = 'lena.png'\n",
        "\n",
        "if not os.path.exists(LENA_IMG):\n",
        "    raise FileNotFoundError(f\"Image not found at {LENA_IMG}\")"
      ],
      "metadata": {
        "id": "QllMGzuii8Ap"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as skimage_ssim\n",
        "\n",
        "\n",
        "class StegoMetrics:\n",
        "    def __init__(self, ori_image):\n",
        "        \"\"\"\n",
        "        Initialize the StegoMetrics class with the original image path.\n",
        "\n",
        "        Args:\n",
        "            ori_image (str): Path to the original image.\n",
        "        \"\"\"\n",
        "        self.ori_image = ori_image\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_mse(original, stego):\n",
        "        \"\"\"\n",
        "        Calculate the Mean Squared Error (MSE) between two images.\n",
        "\n",
        "        Args:\n",
        "            original (numpy.ndarray): Original image array.\n",
        "            stego (numpy.ndarray): Stego image array.\n",
        "\n",
        "        Returns:\n",
        "            float: The MSE value.\n",
        "        \"\"\"\n",
        "        return np.mean((original - stego) ** 2)\n",
        "\n",
        "    def calculate_psnr(self, stego_image_path):\n",
        "        \"\"\"\n",
        "        Calculate the Peak Signal-to-Noise Ratio (PSNR) between the original and stego image.\n",
        "\n",
        "        Args:\n",
        "            stego_image_path (str): Path to the stego image.\n",
        "\n",
        "        Returns:\n",
        "            float: The PSNR value.\n",
        "        \"\"\"\n",
        "        # Read images\n",
        "        original = cv2.imread(self.ori_image)\n",
        "        stego = cv2.imread(stego_image_path)\n",
        "\n",
        "        if original is None:\n",
        "            raise ValueError(f\"Failed to load original image from {self.ori_image}. Ensure the file exists and is a valid image format.\")\n",
        "        if stego is None:\n",
        "            raise ValueError(f\"Failed to load stego image from {stego_image_path}. Ensure the file exists and is a valid image format.\")\n",
        "\n",
        "        # Calculate MSE\n",
        "        mse = self.calculate_mse(original, stego)\n",
        "        if mse == 0:  # If images are identical\n",
        "            return float('inf')\n",
        "\n",
        "        # Calculate PSNR\n",
        "        max_pixel_value = 255.0\n",
        "        psnr = 10 * np.log10((max_pixel_value ** 2) / mse)\n",
        "        return psnr\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_ssim(original, stego):\n",
        "        \"\"\"\n",
        "        Calculate the Structural Similarity Index (SSIM) between two images.\n",
        "\n",
        "        Args:\n",
        "            original (numpy.ndarray): Original image array.\n",
        "            stego (numpy.ndarray): Stego image array.\n",
        "\n",
        "        Returns:\n",
        "            float: The SSIM value.\n",
        "        \"\"\"\n",
        "        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
        "        stego_gray = cv2.cvtColor(stego, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        ssim_value, _ = skimage_ssim(original_gray, stego_gray, full=True)\n",
        "        return ssim_value\n",
        "\n",
        "\n",
        "    def calculate_metrics(self, stego_image_path):\n",
        "        \"\"\"\n",
        "        Calculate MSE, PSNR, and SSIM between the original and stego image.\n",
        "\n",
        "        Args:\n",
        "            stego_image_path (str): Path to the stego image.\n",
        "\n",
        "        Returns:\n",
        "            tuple: MSE, PSNR, and SSIM values.\n",
        "        \"\"\"\n",
        "        # Read images\n",
        "        original = cv2.imread(self.ori_image)\n",
        "        stego = cv2.imread(stego_image_path)\n",
        "\n",
        "        if original is None:\n",
        "            raise ValueError(f\"Failed to load original image from {self.ori_image}. Ensure the file exists and is a valid image format.\")\n",
        "        if stego is None:\n",
        "            raise ValueError(f\"Failed to load stego image from {stego_image_path}. Ensure the file exists and is a valid image format.\")\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse_value = self.calculate_mse(original, stego)\n",
        "        psnr_value = self.calculate_psnr(stego_image_path)\n",
        "        ssim_value = self.calculate_ssim(original, stego)\n",
        "\n",
        "        print(f'Metrics between original ({self.ori_image}) and stego image ({stego_image_path}):')\n",
        "        print(f'MSE: {mse_value}')\n",
        "        print(f'PSNR: {psnr_value}')\n",
        "        print(f'SSIM: {ssim_value}')\n",
        "\n",
        "        return mse_value, psnr_value, ssim_value"
      ],
      "metadata": {
        "id": "55F5SypGjTOp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_image_path = 'lena.png'\n",
        "stego_metrics = StegoMetrics(ori_image=original_image_path)"
      ],
      "metadata": {
        "id": "uDg0sn2WjXNp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def message_to_bit(message, bit_length=8):\n",
        "    \"\"\"\n",
        "    Convert a text message into a binary string with a specified bit length per character.\n",
        "    \"\"\"\n",
        "    return ''.join(format(ord(char), f'0{bit_length}b') for char in message)\n",
        "\n",
        "def bit_to_message(bit_string, bit_length=8):\n",
        "    \"\"\"\n",
        "    Convert a binary string back into a text message using the specified bit length per character.\n",
        "    \"\"\"\n",
        "    if len(bit_string) % bit_length != 0:\n",
        "        raise ValueError(\"Invalid bit string length for the specified bit length.\")\n",
        "\n",
        "    chars = [bit_string[i:i+bit_length] for i in range(0, len(bit_string), bit_length)]\n",
        "    return ''.join(chr(int(char, 2)) for char in chars)"
      ],
      "metadata": {
        "id": "051CGW9GjLdp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bits(bits):\n",
        "    \"\"\"\n",
        "    Convert bits to kilobytes (KB), megabytes (MB), gigabytes (GB), and terabytes (TB).\n",
        "    \"\"\"\n",
        "    bytes_value = bits / 8\n",
        "    kb_value = bytes_value / 1024\n",
        "    mb_value = kb_value / 1024\n",
        "    gb_value = mb_value / 1024\n",
        "    tb_value = gb_value / 1024\n",
        "\n",
        "    print(f\"{bits} bits is:\")\n",
        "    print(f\"{kb_value:.2f} KB\")\n",
        "    print(f\"{mb_value:.4f} MB\")\n",
        "    print(f\"{gb_value:.6f} GB\")\n",
        "    print(f\"{tb_value:.9f} TB\")  # More precision for TB\n",
        "    print()"
      ],
      "metadata": {
        "id": "PzUSH1GgjMlK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def format_file_size(size_in_bytes):\n",
        "    \"\"\"\n",
        "    Convert a file size in bytes to a human-readable format (KB, MB, GB, etc.).\n",
        "\n",
        "    Args:\n",
        "        size_in_bytes (int): The size of the file in bytes.\n",
        "\n",
        "    Returns:\n",
        "        str: The size in a human-readable format.\n",
        "    \"\"\"\n",
        "    if size_in_bytes < 1024:\n",
        "        return f\"{size_in_bytes} Bytes\"\n",
        "    elif size_in_bytes < 1024 ** 2:\n",
        "        return f\"{size_in_bytes / 1024:.2f} KB\"\n",
        "    elif size_in_bytes < 1024 ** 3:\n",
        "        return f\"{size_in_bytes / (1024 ** 2):.2f} MB\"\n",
        "    elif size_in_bytes < 1024 ** 4:\n",
        "        return f\"{size_in_bytes / (1024 ** 3):.2f} GB\"\n",
        "    else:\n",
        "        return f\"{size_in_bytes / (1024 ** 4):.2f} TB\"\n",
        "\n",
        "def print_png_file_sizes(output_image_path, input_image_path='lena.png',file_format=\"png\"):\n",
        "    \"\"\"\n",
        "    Function to read and print the sizes of two PNG files in a human-readable format.\n",
        "\n",
        "    Args:\n",
        "        input_image_path (str): Full path to the input PNG file.\n",
        "        output_image_path (str): Full path to the output PNG file.\n",
        "    \"\"\"\n",
        "    for file_path in [input_image_path, output_image_path]:\n",
        "        if os.path.isfile(file_path) and file_path.lower().endswith(f'.{file_format.lower()}'):\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            human_readable_size = format_file_size(file_size)\n",
        "            print(f\"The size of the file '{file_path}' is: {human_readable_size}\")\n",
        "        else:\n",
        "            print(f\"File '{file_path}' not found or it is not a {file_format.upper()} file.\")"
      ],
      "metadata": {
        "id": "uyqOG-yojN_C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class LeastSignificantBit:\n",
        "    def __init__(self, k_val=1):\n",
        "        \"\"\"\n",
        "        Initialize the LeastSignificantBit class.\n",
        "\n",
        "        Args:\n",
        "            k_val (int): The number of least significant bits to use for embedding.\n",
        "        \"\"\"\n",
        "        if not (1 <= k_val <= 8):\n",
        "            raise ValueError(\"k_val must be between 1 and 8.\")\n",
        "        self.k_val = k_val\n",
        "\n",
        "    def calculate_max_message_size(self, image_path):\n",
        "        \"\"\"\n",
        "        Calculate the maximum number of characters that can be stored in an image\n",
        "        using the dynamic encoding method.\n",
        "\n",
        "        Returns:\n",
        "            max_chars (int): The maximum number of characters that can be stored.\n",
        "            max_bits (int): The total number of usable bits for message storage.\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path)\n",
        "        img_data = np.array(image)\n",
        "\n",
        "        # Calculate total bit capacity\n",
        "        height, width, channels = img_data.shape\n",
        "        total_capacity_bits = height * width * channels * self.k_val\n",
        "\n",
        "        total_capacity_bits = total_capacity_bits - 32\n",
        "\n",
        "        max_chars = total_capacity_bits // 8\n",
        "\n",
        "        max_bits = total_capacity_bits\n",
        "\n",
        "        return max_chars, max_bits\n",
        "\n",
        "    def message_to_bits(self, message_bits):\n",
        "        \"\"\"\n",
        "        Convert a string message to a bit string, using a dynamically determined bit length for the message size.\n",
        "        \"\"\"\n",
        "        message_length = len(message_bits)\n",
        "        print(message_length)\n",
        "\n",
        "        message_length_bits = format(message_length, f'032b')\n",
        "\n",
        "        return message_length_bits + message_bits\n",
        "\n",
        "    def bits_to_message(self, bits):\n",
        "        \"\"\"\n",
        "        Convert a bit string back to a human-readable message, using dynamically encoded message length.\n",
        "        \"\"\"\n",
        "        message_length_bit = bits[:32]\n",
        "\n",
        "        message_length = int(message_length_bit, 2)\n",
        "        print(message_length)\n",
        "\n",
        "        message_bits = bits[32:32 + message_length]\n",
        "\n",
        "        return message_bits\n",
        "\n",
        "    @staticmethod\n",
        "    def change_n_lsb(binary_number, new_lsbs, k_val):\n",
        "        \"\"\"\n",
        "        Modify the n least significant bits (LSBs) of a binary number.\n",
        "        \"\"\"\n",
        "        binary_literal = int(new_lsbs, 2)\n",
        "        mask = ~((1 << k_val) - 1) & 0xFF\n",
        "        return (binary_number & mask) | binary_literal\n",
        "\n",
        "    def embed_message(self, input_image_path, output_image_path, message):\n",
        "        \"\"\"\n",
        "        Modify pixel values of an image to embed a message.\n",
        "        \"\"\"\n",
        "        message_bits = self.message_to_bits(message)\n",
        "\n",
        "        image = Image.open(input_image_path)\n",
        "        img_data = np.array(image)\n",
        "\n",
        "        height, width, channels = img_data.shape\n",
        "        # capacity = height * width * channels * self.k_val\n",
        "        # if len(message_bits) > capacity:\n",
        "        #     raise ValueError(f\"Message too long! Capacity: {capacity} bits, Message: {len(message_bits)} bits.\")\n",
        "\n",
        "            # Calculate maximum capacity\n",
        "\n",
        "        bit_idx = 0\n",
        "        for h in range(height):\n",
        "            for w in range(width):\n",
        "                for c in range(channels):\n",
        "                    if bit_idx < len(message_bits):\n",
        "                        original_value = img_data[h, w, c]\n",
        "                        bits_to_embed = message_bits[bit_idx:bit_idx + self.k_val]\n",
        "                        bits_to_embed = bits_to_embed.ljust(self.k_val, '0')\n",
        "\n",
        "                        img_data[h, w, c] = self.change_n_lsb(original_value, bits_to_embed, self.k_val)\n",
        "                        bit_idx += self.k_val\n",
        "                if bit_idx >= len(message_bits):\n",
        "                    break\n",
        "            if bit_idx >= len(message_bits):\n",
        "                break\n",
        "\n",
        "        stego_image = Image.fromarray(img_data)\n",
        "        stego_image.save(output_image_path, format=\"PNG\")\n",
        "        return stego_image\n",
        "\n",
        "    def extract_message(self, stego_image_path):\n",
        "        \"\"\"\n",
        "        Extract a hidden message from an image that uses LSB encoding.\n",
        "        \"\"\"\n",
        "        image = Image.open(stego_image_path)\n",
        "        img_data = np.array(image)\n",
        "\n",
        "        height, width, channels = img_data.shape\n",
        "        extracted_bits = \"\"\n",
        "\n",
        "        for h in range(height):\n",
        "            for w in range(width):\n",
        "                for c in range(channels):\n",
        "                    pixel_value = img_data[h, w, c]\n",
        "                    lsb_bits = format(pixel_value, '08b')[-self.k_val:]\n",
        "                    extracted_bits += lsb_bits\n",
        "\n",
        "        # Ensure that we are extracting the correct number of bits\n",
        "        return self.bits_to_message(extracted_bits)\n",
        "\n"
      ],
      "metadata": {
        "id": "QFWtKvGoi8fh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4\n",
        "lsb = LeastSignificantBit(k_val=k)\n",
        "\n",
        "input_image_path = 'lena.png'\n",
        "output_image_path = 'lsb.png'\n",
        "\n",
        "max_chars, max_bits = lsb.calculate_max_message_size(input_image_path)\n",
        "repeated_data = (merged_ktps[0] * (max_chars // len(merged_ktps[0]) + 1))[:max_chars]\n",
        "\n",
        "message = message_to_bit(repeated_data)\n",
        "\n",
        "_ = lsb.embed_message(input_image_path, output_image_path, message)\n",
        "\n",
        "extracted_message = lsb.extract_message(output_image_path)\n",
        "\n",
        "return_message = bit_to_message(extracted_message)\n",
        "\n",
        "assert repeated_data == return_message\n",
        "\n",
        "convert_bits(len(message_to_bit(repeated_data)))\n",
        "\n",
        "stego_metrics.calculate_metrics(output_image_path)\n",
        "\n",
        "print_png_file_sizes(output_image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVctbaVOjG8x",
        "outputId": "b48f5145-df72-4e5a-bf87-5ca2d26a260f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3145696\n",
            "3145696\n",
            "3145696 bits is:\n",
            "384.00 KB\n",
            "0.3750 MB\n",
            "0.000366 GB\n",
            "0.000000358 TB\n",
            "\n",
            "Metrics between original (lena.png) and stego image (lsb.png):\n",
            "MSE: 39.513840993245445\n",
            "PSNR: 32.163311129861874\n",
            "SSIM: 0.906491868493046\n",
            "The size of the file 'lena.png' is: 468.53 KB\n",
            "The size of the file 'lsb.png' is: 351.93 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjW1_ZV5mWHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4\n",
        "lsb = LeastSignificantBit(k_val=k)\n",
        "\n",
        "input_image_path = '/content/jeri.jpg'\n",
        "output_image_path = 'jeri_lsb.jpg'\n",
        "\n",
        "max_chars, max_bits = lsb.calculate_max_message_size(input_image_path)\n",
        "repeated_data = (merged_ktps[0] * (max_chars // len(merged_ktps[0]) + 1))[:max_chars]\n",
        "\n",
        "message = message_to_bit(repeated_data)\n",
        "\n",
        "_ = lsb.embed_message(input_image_path, output_image_path, message)\n",
        "\n",
        "extracted_message = lsb.extract_message(output_image_path)\n",
        "\n",
        "return_message = bit_to_message(extracted_message)\n",
        "\n",
        "assert repeated_data == return_message\n",
        "\n",
        "convert_bits(len(message_to_bit(repeated_data)))\n",
        "\n",
        "# stego_metrics.calculate_metrics(output_image_path)\n",
        "\n",
        "print_png_file_sizes(output_image_path, input_image_path, 'jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKhx0dQBjjQq",
        "outputId": "3dc73204-cb35-4236-aadd-438b47eaf7dd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4078344\n",
            "4078344\n",
            "4078344 bits is:\n",
            "497.84 KB\n",
            "0.4862 MB\n",
            "0.000475 GB\n",
            "0.000000464 TB\n",
            "\n",
            "The size of the file '/content/jeri.jpg' is: 156.46 KB\n",
            "The size of the file 'jeri_lsb.jpg' is: 197.27 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_len = len(repeated_data)\n",
        "base_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbzsHr49md7y",
        "outputId": "61193c6c-9d61-44db-f395-35c8b5561fd4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "509793"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Compress"
      ],
      "metadata": {
        "id": "Q1eCyTHOjYvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class LZW:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.compressionDictionary, self.compressionIndex = self.createCompressionDict()\n",
        "        self.decompressionDictionary, self.decompressionIndex = self.createDecompressionDict()\n",
        "\n",
        "    ''''''\n",
        "    ''' --------------------- Compression of the Image --------------------- '''\n",
        "    ''''''\n",
        "\n",
        "    def compress(self):\n",
        "        self.initCompress()\n",
        "        compressedcColors = []\n",
        "        print(\"Compressing Image ...\")\n",
        "        compressedcColors.append(self.compressColor(self.red))\n",
        "        print(\"Compressing Image ...\")\n",
        "        compressedcColors.append(self.compressColor(self.green))\n",
        "        print(\"Compressing Image ...\")\n",
        "        compressedcColors.append(self.compressColor(self.blue))\n",
        "        print(\"Image Compressed --------- Writing to File\")\n",
        "        filesplit = str(os.path.basename(self.path)).split('.')\n",
        "        filename = filesplit[0] + 'Compressed.lzw'\n",
        "        savingDirectory = os.path.join(os.getcwd(),'CompressedFiles')\n",
        "        if not os.path.isdir(savingDirectory):\n",
        "            os.makedirs(savingDirectory)\n",
        "        with open(os.path.join(savingDirectory,filename),'w') as file:\n",
        "            for color in compressedcColors:\n",
        "                for row in color:\n",
        "                    file.write(row)\n",
        "                    file.write(\"\\n\")\n",
        "\n",
        "    def compressColor(self, colorList):\n",
        "        compressedColor = []\n",
        "        i = 0\n",
        "        for currentRow in colorList:\n",
        "            currentString = currentRow[0]\n",
        "            compressedRow = \"\"\n",
        "            i+=1\n",
        "            for charIndex in range(1, len(currentRow)):\n",
        "                currentChar = currentRow[charIndex]\n",
        "                if currentString+currentChar in self.compressionDictionary:\n",
        "                    currentString = currentString+currentChar\n",
        "                else:\n",
        "                    compressedRow = compressedRow + str(self.compressionDictionary[currentString]) + \",\"\n",
        "                    self.compressionDictionary[currentString+currentChar] = self.compressionIndex\n",
        "                    self.compressionIndex += 1\n",
        "                    currentString = currentChar\n",
        "                currentChar = \"\"\n",
        "            compressedRow = compressedRow + str(self.compressionDictionary[currentString])\n",
        "            compressedColor.append(compressedRow)\n",
        "        return compressedColor\n",
        "\n",
        "    ''''''\n",
        "    ''' --------------------- Deompression of the Image --------------------- '''\n",
        "    ''''''\n",
        "\n",
        "    def decompress(self):\n",
        "        print(\"Decompressing File ...\")\n",
        "        image = []\n",
        "        with open(self.path,\"r\") as file:\n",
        "            for line in file:\n",
        "                decodedRow = self.decompressRow(line)\n",
        "                image.append(np.array(decodedRow))\n",
        "        image = np.array(image)\n",
        "        shapeTup = image.shape\n",
        "        image = image.reshape((3,shapeTup[0]//3,shapeTup[1]))\n",
        "        self.saveImage(image)\n",
        "        print(\"Decompression Done.\")\n",
        "\n",
        "    def decompressRow(self,line):\n",
        "        currentRow = line.split(\",\")\n",
        "        currentRow[-1] = currentRow[-1][:-1]\n",
        "        decodedRow = \"\"\n",
        "        word,entry = \"\",\"\"\n",
        "        decodedRow = decodedRow + self.decompressionDictionary[int(currentRow[0])]\n",
        "        word = self.decompressionDictionary[int(currentRow[0])]\n",
        "        for i in range(1,len(currentRow)):\n",
        "            new = int(currentRow[i])\n",
        "            if new in self.decompressionDictionary:\n",
        "                entry = self.decompressionDictionary[new]\n",
        "                decodedRow += entry\n",
        "                add = word + entry[0]\n",
        "                word = entry\n",
        "            else:\n",
        "                entry = word + word[0]\n",
        "                decodedRow += entry\n",
        "                add = entry\n",
        "                word = entry\n",
        "            self.decompressionDictionary[self.decompressionIndex] = add\n",
        "            self.decompressionIndex+=1\n",
        "        newRow = decodedRow.split(',')\n",
        "        decodedRow = [int(x) for x in newRow]\n",
        "        return decodedRow\n",
        "\n",
        "    ''''''\n",
        "    ''' ---------------------- Class Helper Functions ---------------------- '''\n",
        "    ''''''\n",
        "\n",
        "    '''\n",
        "    Used For: Compression of Image\n",
        "    Function: This function breaks down the image into the three constituting\n",
        "              image chanels - Red, Green and Blue.\n",
        "    '''\n",
        "    def initCompress(self):\n",
        "        self.image = Image.open(self.path)\n",
        "        self.height, self.width = self.image.size\n",
        "        self.red, self.green, self.blue = self.processImage()\n",
        "\n",
        "    '''\n",
        "    Used For: Compression of Image\n",
        "    Function: This function breaks down the image into the three constituting\n",
        "              image chanels - Red, Green and Blue.\n",
        "    '''\n",
        "    def processImage(self):\n",
        "        image = self.image.convert('RGB')\n",
        "        red, green, blue = [], [], []\n",
        "        pixel_values = list(image.getdata())\n",
        "        iterator = 0\n",
        "        for height_index in range(self.height):\n",
        "            R, G, B = \"\",\"\",\"\"\n",
        "            for width_index in range(self.width):\n",
        "                RGB = pixel_values[iterator]\n",
        "                R = R + str(RGB[0]) + \",\"\n",
        "                G = G + str(RGB[1]) + \",\"\n",
        "                B = B + str(RGB[2]) + \",\"\n",
        "                iterator+=1\n",
        "            red.append(R[:-1])\n",
        "            green.append(G[:-1])\n",
        "            blue.append(B[:-1])\n",
        "        return red,green,blue\n",
        "\n",
        "\n",
        "    '''\n",
        "    Used For: Decompression of Image\n",
        "    Function: This function will save the decompressed image as <name>.jpg\n",
        "    '''\n",
        "    def saveImage(self,image):\n",
        "        print(\"Saving Decompressed File...\")\n",
        "        filesplit = str(os.path.basename(self.path)).split('Compressed.lzw')\n",
        "        filename = filesplit[0] + \"Decompressed.jpg\"\n",
        "        savingDirectory = os.path.join(os.getcwd(),'DecompressedFiles')\n",
        "        if not os.path.isdir(savingDirectory):\n",
        "            os.makedirs(savingDirectory)\n",
        "        imagelist,imagesize = self.makeImageData(image[0],image[1],image[2])\n",
        "        imagenew = Image.new('RGB',imagesize)\n",
        "        imagenew.putdata(imagelist)\n",
        "        imagenew.save(os.path.join(savingDirectory,filename))\n",
        "\n",
        "    '''\n",
        "    Used For: Decompression of Image\n",
        "    Function: This function will convert and return the image in the (r,g,b) format\n",
        "              to save the image.\n",
        "    '''\n",
        "    def makeImageData(self,r,g,b):\n",
        "        imagelist = []\n",
        "        for i in range(len(r)):\n",
        "            for j in range(len(r[0])):\n",
        "                imagelist.append((r[i][j],g[i][j],b[i][j]))\n",
        "        return imagelist,(len(r),len(r[0]))\n",
        "\n",
        "    '''\n",
        "    Used For: Compression of Image\n",
        "    Function: This function will initialise the compression dictionary\n",
        "    '''\n",
        "    def createCompressionDict(self):\n",
        "        dictionary = {}\n",
        "        for i in range(10):\n",
        "            dictionary[str(i)] = i\n",
        "        dictionary[','] = 10\n",
        "        return dictionary,11\n",
        "\n",
        "    '''\n",
        "    Used For: Compression of Image\n",
        "    Function: This function will initialise the decompression dictionary\n",
        "    '''\n",
        "    def createDecompressionDict(self):\n",
        "        dictionary = {}\n",
        "        for i in range(10):\n",
        "            dictionary[i] = str(i)\n",
        "        dictionary[10] = ','\n",
        "        return dictionary,11"
      ],
      "metadata": {
        "id": "pkf7lzR9ja_x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "compressor = LZW('jeri_lsb.jpg')\n",
        "compressor.compress()\n",
        "\n",
        "decompressor = LZW(os.path.join(\"CompressedFiles\",\"jeri_lsbCompressed.lzw\"))\n",
        "decompressor.decompress()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvypdL6akr47",
        "outputId": "309eab3a-78db-4ec2-fa6f-d1658537cf2b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compressing Image ...\n",
            "Compressing Image ...\n",
            "Compressing Image ...\n",
            "Image Compressed --------- Writing to File\n",
            "Decompressing File ...\n",
            "Saving Decompressed File...\n",
            "Decompression Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "import os\n",
        "\n",
        "# Helper functions for reading and writing images\n",
        "def read_image_bit_string(path):\n",
        "    with open(path, 'rb') as image:\n",
        "        bit_string = \"\"\n",
        "        byte = image.read(1)\n",
        "        while (len(byte) > 0):\n",
        "            byte = ord(byte)\n",
        "            bits = bin(byte)[2:].rjust(8, '0')\n",
        "            bit_string += bits\n",
        "            byte = image.read(1)\n",
        "    return bit_string\n",
        "\n",
        "\n",
        "def write_image(bit_string, path):\n",
        "    with open(path, 'wb') as image:\n",
        "        for i in range(0, len(bit_string), 8):\n",
        "            byte = bit_string[i:i + 8]\n",
        "            image.write(bytes([int(byte, 2)]))\n",
        "\n",
        "\n",
        "def write_dictionary_file(dictionary, path):\n",
        "    with open(path, 'w') as f:\n",
        "        for key, value in dictionary.items():\n",
        "            f.write('%s:%s\\n' % (key, value))\n",
        "\n",
        "\n",
        "# Huffman coding related functions\n",
        "class node:\n",
        "    def __init__(self, frequency, symbol, left=None, right=None):\n",
        "        self.frequency = frequency\n",
        "        self.symbol = symbol\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.huffman_direction = ''\n",
        "\n",
        "    def __lt__(self, nxt):\n",
        "        return self.frequency < nxt.frequency\n",
        "\n",
        "\n",
        "huffman_codes = {}\n",
        "\n",
        "def get_compressed_image(image_bit_string):\n",
        "    compressed_image_bit_string = \"\"\n",
        "    for i in range(0, len(image_bit_string), 8):\n",
        "        byte = image_bit_string[i:i + 8]\n",
        "        compressed_image_bit_string += huffman_codes[byte]\n",
        "    return compressed_image_bit_string\n",
        "\n",
        "\n",
        "def calculate_huffman_codes(node, code=''):\n",
        "    code += node.huffman_direction\n",
        "    if node.left:\n",
        "        calculate_huffman_codes(node.left, code)\n",
        "    if node.right:\n",
        "        calculate_huffman_codes(node.right, code)\n",
        "    if not node.left and not node.right:\n",
        "        huffman_codes[node.symbol] = code\n",
        "    return huffman_codes\n",
        "\n",
        "\n",
        "def get_merged_huffman_tree(byte_to_frequency):\n",
        "    huffman_tree = []\n",
        "    for byte, frequency in byte_to_frequency.items():\n",
        "        heapq.heappush(huffman_tree, node(frequency, byte))\n",
        "    while len(huffman_tree) > 1:\n",
        "        left = heapq.heappop(huffman_tree)\n",
        "        right = heapq.heappop(huffman_tree)\n",
        "        left.huffman_direction = \"0\"\n",
        "        right.huffman_direction = \"1\"\n",
        "        merged_node = node(left.frequency + right.frequency,\n",
        "                           left.symbol + right.symbol, left, right)\n",
        "        heapq.heappush(huffman_tree, merged_node)\n",
        "    return huffman_tree[0]\n",
        "\n",
        "\n",
        "def get_frequency(image_bit_string):\n",
        "    byte_to_frequency = {}\n",
        "    for i in range(0, len(image_bit_string), 8):\n",
        "        byte = image_bit_string[i:i + 8]\n",
        "        if byte not in byte_to_frequency:\n",
        "            byte_to_frequency[byte] = 0\n",
        "        byte_to_frequency[byte] += 1\n",
        "    return byte_to_frequency\n",
        "\n",
        "\n",
        "def compress(image_bit_string):\n",
        "    byte_to_frequency = get_frequency(image_bit_string)\n",
        "    merged_huffman_tree = get_merged_huffman_tree(byte_to_frequency)\n",
        "    calculate_huffman_codes(merged_huffman_tree)\n",
        "    return get_compressed_image(image_bit_string)\n",
        "\n",
        "\n",
        "def decompress(compressed_image_bit_string):\n",
        "    decompressed_image_bit_string = \"\"\n",
        "    current_code = \"\"\n",
        "    for bit in compressed_image_bit_string:\n",
        "        current_code += bit\n",
        "        for byte, code in huffman_codes.items():\n",
        "            if current_code == code:\n",
        "                decompressed_image_bit_string += byte\n",
        "                current_code = \"\"\n",
        "    return decompressed_image_bit_string\n",
        "\n",
        "\n",
        "# Main function to handle compression and decompression\n",
        "def process_image(image_path, output_dir=\"./IO/Outputs\"):\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Read image and get its bit string\n",
        "    image_bit_string = read_image_bit_string(image_path)\n",
        "\n",
        "    # Compress the image\n",
        "    compressed_image_bit_string = compress(image_bit_string)\n",
        "    compressed_image_path = os.path.join(output_dir, \"compressed_image_jeri.bin\")\n",
        "    write_image(compressed_image_bit_string, compressed_image_path)\n",
        "\n",
        "    # Print the compression ratio\n",
        "    print(\"Compression Ratio (CR):\", len(image_bit_string) / len(compressed_image_bit_string))\n",
        "\n",
        "    # Decompress the image\n",
        "    decompressed_image_bit_string = decompress(compressed_image_bit_string)\n",
        "    decompressed_image_path = os.path.join(output_dir, \"decompressed_image_jeri.jpg\")\n",
        "    write_image(decompressed_image_bit_string, decompressed_image_path)\n",
        "\n",
        "    return compressed_image_path, decompressed_image_path\n",
        "\n"
      ],
      "metadata": {
        "id": "8x-oqsWFk7aq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_path = \"jeri_lsb.jpg\"  # Provide the path to your image\n",
        "compressed_image_path, decompressed_image_path = process_image(image_path)\n",
        "\n",
        "print(f\"Compressed image saved to: {compressed_image_path}\")\n",
        "print(f\"Decompressed image saved to: {decompressed_image_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdn0hRhyk7xZ",
        "outputId": "72a4daea-24d5-4924-d12a-659c7140cad8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compression Ratio (CR): 1.0005820159546672\n",
            "Compressed image saved to: ./IO/Outputs/compressed_image_jeri.bin\n",
            "Decompressed image saved to: ./IO/Outputs/decompressed_image_jeri.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Compress"
      ],
      "metadata": {
        "id": "erbKLSrTlNO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class HuffmanNode:\n",
        "    def __init__(self, char, freq):\n",
        "        self.char = char\n",
        "        self.freq = freq\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.freq < other.freq\n",
        "\n",
        "\n",
        "class HuffmanCoding:\n",
        "    @staticmethod\n",
        "    def build_frequency_table(text):\n",
        "        \"\"\"Build a frequency table for the given text.\"\"\"\n",
        "        return Counter(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_huffman_tree(freq_table):\n",
        "        \"\"\"Build the Huffman Tree based on the frequency table.\"\"\"\n",
        "        heap = [HuffmanNode(char, freq) for char, freq in freq_table.items()]\n",
        "        heapq.heapify(heap)\n",
        "\n",
        "        while len(heap) > 1:\n",
        "            left = heapq.heappop(heap)\n",
        "            right = heapq.heappop(heap)\n",
        "            merged = HuffmanNode(None, left.freq + right.freq)\n",
        "            merged.left = left\n",
        "            merged.right = right\n",
        "            heapq.heappush(heap, merged)\n",
        "\n",
        "        return heap[0] if heap else None\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_huffman_codes(node, prefix='', codebook=None):\n",
        "        \"\"\"Recursively generate Huffman codes for each character.\"\"\"\n",
        "        if codebook is None:\n",
        "            codebook = {}\n",
        "        if node is None:\n",
        "            return codebook\n",
        "\n",
        "        if node.char is not None:\n",
        "            codebook[node.char] = prefix\n",
        "        else:\n",
        "            HuffmanCoding.generate_huffman_codes(\n",
        "                node.left, prefix + '0', codebook)\n",
        "            HuffmanCoding.generate_huffman_codes(\n",
        "                node.right, prefix + '1', codebook)\n",
        "\n",
        "        return codebook\n",
        "\n",
        "    @staticmethod\n",
        "    def encode(text, codebook):\n",
        "        \"\"\"Encode the input text using the Huffman codebook.\"\"\"\n",
        "        bitstring = ''.join(codebook[char] for char in text)\n",
        "        return bitstring\n",
        "\n",
        "    @staticmethod\n",
        "    def decode(bitstring, huffman_tree):\n",
        "        \"\"\"Decode the encoded bitstring back to the original text.\"\"\"\n",
        "        decoded_text = []\n",
        "        node = huffman_tree\n",
        "\n",
        "        for bit in bitstring:\n",
        "            node = node.left if bit == '0' else node.right\n",
        "            if node.char is not None:\n",
        "                decoded_text.append(node.char)\n",
        "                node = huffman_tree\n",
        "\n",
        "        return ''.join(decoded_text)\n",
        "\n",
        "    @staticmethod\n",
        "    def build_huffman(text):\n",
        "        \"\"\"Build the Huffman tree, generate codes, and encode the text.\"\"\"\n",
        "        freq_table = HuffmanCoding.build_frequency_table(text)\n",
        "\n",
        "        huffman_tree = HuffmanCoding.build_huffman_tree(freq_table)\n",
        "\n",
        "        codebook = HuffmanCoding.generate_huffman_codes(huffman_tree)\n",
        "\n",
        "        encoded_text = HuffmanCoding.encode(text, codebook)\n",
        "\n",
        "        return encoded_text, huffman_tree"
      ],
      "metadata": {
        "id": "9k1lwqoFlOqx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LZW:\n",
        "    def __init__(self):\n",
        "        self.dictionary_size = 256\n",
        "\n",
        "    def compress(self, input_string):\n",
        "        \"\"\"\n",
        "        Compress a string using LZW algorithm and return a 32-bit encoded bit string.\n",
        "        \"\"\"\n",
        "        if not input_string:\n",
        "            return \"\"\n",
        "\n",
        "        # Initialize dictionary\n",
        "        dictionary = {chr(i): i for i in range(self.dictionary_size)}\n",
        "        next_code = self.dictionary_size\n",
        "\n",
        "        current_string = \"\"\n",
        "        compressed_data = []\n",
        "\n",
        "        for char in input_string:\n",
        "            current_string_plus_char = current_string + char\n",
        "            if current_string_plus_char in dictionary:\n",
        "                current_string = current_string_plus_char\n",
        "            else:\n",
        "                compressed_data.append(dictionary[current_string])\n",
        "                dictionary[current_string_plus_char] = next_code\n",
        "                next_code += 1\n",
        "                current_string = char\n",
        "\n",
        "        if current_string:\n",
        "            compressed_data.append(dictionary[current_string])\n",
        "\n",
        "        # Convert compressed codes to 32-bit binary strings\n",
        "        bit_output = ''.join(format(code, '032b') for code in compressed_data)\n",
        "        return bit_output\n",
        "\n",
        "    def decompress(self, compressed_bits):\n",
        "        \"\"\"\n",
        "        Decompress a 32-bit encoded bit string back into the original message.\n",
        "        \"\"\"\n",
        "        if not compressed_bits:\n",
        "            return \"\"\n",
        "\n",
        "        # Convert 32-bit binary chunks back to integer codes\n",
        "        compressed_data = [int(compressed_bits[i:i+32], 2) for i in range(0, len(compressed_bits), 32)]\n",
        "\n",
        "        # Initialize dictionary\n",
        "        dictionary = {i: chr(i) for i in range(self.dictionary_size)}\n",
        "        next_code = self.dictionary_size\n",
        "\n",
        "        current_code = compressed_data[0]\n",
        "        decompressed_string = dictionary[current_code]\n",
        "        current_string = decompressed_string\n",
        "\n",
        "        for code in compressed_data[1:]:\n",
        "            if code in dictionary:\n",
        "                entry = dictionary[code]\n",
        "            elif code == next_code:\n",
        "                entry = current_string + current_string[0]\n",
        "            decompressed_string += entry\n",
        "\n",
        "            dictionary[next_code] = current_string + entry[0]\n",
        "            next_code += 1\n",
        "            current_string = entry\n",
        "\n",
        "        return decompressed_string\n"
      ],
      "metadata": {
        "id": "7jWvSgm7lRHh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_image_path = 'jeri.jpg'\n",
        "stego_metrics = StegoMetrics(ori_image=original_image_path)"
      ],
      "metadata": {
        "id": "hQjDxIgoll4i"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4\n",
        "lsb = LeastSignificantBit(k_val=k)\n",
        "\n",
        "input_image_path = 'jeri.jpg'\n",
        "output_image_path = 'lsbhuffman.jpg'\n",
        "\n",
        "max_chars, max_bits = lsb.calculate_max_message_size(input_image_path)\n",
        "repeated_data = (merged_ktps[0] * (base_len // len(merged_ktps[0]) + 1))[:base_len]\n",
        "\n",
        "huffman = HuffmanCoding()\n",
        "\n",
        "compressed_message, huffman_tree = huffman.build_huffman(repeated_data) # it take message and return bits\n",
        "\n",
        "stego_image = lsb.embed_message(input_image_path, output_image_path, compressed_message)\n",
        "img_data = np.array(stego_image)\n",
        "extracted_message = lsb.extract_message(output_image_path)\n",
        "\n",
        "decoded_text = huffman.decode(extracted_message, huffman_tree) # it take bits and return message\n",
        "\n",
        "assert repeated_data == decoded_text\n",
        "\n",
        "convert_bits(len(message_to_bit(repeated_data)))\n",
        "\n",
        "stego_metrics.calculate_metrics(output_image_path)\n",
        "\n",
        "print_png_file_sizes(output_image_path, input_image_path, \"jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1kQv4splSb5",
        "outputId": "b137fdde-80fd-4206-b1e5-5f04d6eb4c1a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2680794\n",
            "2680794\n",
            "4078344 bits is:\n",
            "497.84 KB\n",
            "0.4862 MB\n",
            "0.000475 GB\n",
            "0.000000464 TB\n",
            "\n",
            "Metrics between original (jeri.jpg) and stego image (lsbhuffman.jpg):\n",
            "MSE: 29.233365208734842\n",
            "PSNR: 33.472015486763745\n",
            "SSIM: 0.8986987540036043\n",
            "The size of the file 'jeri.jpg' is: 156.46 KB\n",
            "The size of the file 'lsbhuffman.jpg' is: 283.21 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4\n",
        "lsb = LeastSignificantBit(k_val=k)\n",
        "\n",
        "input_image_path = 'jeri.jpg'\n",
        "output_image_path = 'lsblzw.jpg'\n",
        "\n",
        "max_chars, max_bits = lsb.calculate_max_message_size(input_image_path)\n",
        "repeated_data = (merged_ktps[0] * (base_len // len(merged_ktps[0]) + 1))[:base_len]\n",
        "\n",
        "lzw = LZW()\n",
        "\n",
        "compressed_bits = lzw.compress(repeated_data)\n",
        "\n",
        "_ = lsb.embed_message(input_image_path, output_image_path, compressed_bits)\n",
        "\n",
        "extracted_message = lsb.extract_message(output_image_path)\n",
        "\n",
        "decompressed_string = lzw.decompress(extracted_message)\n",
        "\n",
        "assert repeated_data == decompressed_string\n",
        "\n",
        "convert_bits(len(message_to_bit(repeated_data)))\n",
        "\n",
        "stego_metrics.calculate_metrics(output_image_path)\n",
        "\n",
        "print_png_file_sizes(output_image_path, input_image_path, \"jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Y0WUwUlUp5",
        "outputId": "20fcf21b-2029-4b39-a6b2-694279cfbea8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422400\n",
            "422400\n",
            "4078344 bits is:\n",
            "497.84 KB\n",
            "0.4862 MB\n",
            "0.000475 GB\n",
            "0.000000464 TB\n",
            "\n",
            "Metrics between original (jeri.jpg) and stego image (lsblzw.jpg):\n",
            "MSE: 8.438195558040203\n",
            "PSNR: 38.86830774783697\n",
            "SSIM: 0.9798511080442989\n",
            "The size of the file 'jeri.jpg' is: 156.46 KB\n",
            "The size of the file 'lsblzw.jpg' is: 373.56 KB\n"
          ]
        }
      ]
    }
  ]
}